{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Machine-Learning-Tokyo/intro-to-DL/blob/master/mnist_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "b3QokrtPMFMA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST model\n",
        "\n",
        "In this notebook we will see how we can train a simple model on the mnist dataset\n",
        "\n",
        "First, we import some necessary packages, like keras for the model, pyplot for plotting the images and numpy for the array caclucations"
      ]
    },
    {
      "metadata": {
        "id": "S4W_uQ3ryGIx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist, fashion_mnist\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import *\n",
        "from keras.activations import softmax, relu\n",
        "import keras.backend as K\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rt1qyRCZMhZA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first thing we need is the data. The data are small (28x28 pixels) gray scale images of hand-written digits.\n",
        "\n",
        "Notice the line\n",
        "\n",
        "\n",
        "```\n",
        "X_train, X_val = X_train / 255.0, X_val / 255.0\n",
        "```\n",
        "\n",
        "Originally the images' pixels have values in [0, 255]\n",
        "However that big values are not easy to be handled by the networks. Thus we usually change the input values to something more \"*model friendly*\".\n",
        "\n",
        "This is called data preprocessing.\n",
        "\n",
        "In our case the preprocessing is just to map the values from [0, 255] to [0. 1]\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ewHzG5VyzWzw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train, Y_train), (X_val, Y_val) = mnist.load_data()\n",
        "# (X_train, Y_train), (X_val, Y_val) = fashion_mnist.load_data()\n",
        "X_train, X_val = X_train / 255.0, X_val / 255.0\n",
        "labels_names = 'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine'\n",
        "# labels_names = 'T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
        "r, c = 3, 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B1__zwt1NYmH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It is very important to know the shape of the arrays we use.\n",
        "\n",
        "All the data that we use when training DL models are actually n-dimensional arrays with some values. No matter if it was originally a video, an image, a voice record or a text, in the end everything is transformed to arrays.\n",
        "The shape of the array is important since the models are built to be able to accept specific kind of arrays regarding the shape"
      ]
    },
    {
      "metadata": {
        "id": "5HSicIdLz9to",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('The shape of the traing data array is:', X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b4mPcD5QOLCn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the next cell we define some functions for getting random images from the dataset and plotting them. Don't pay too much attention to them for the moment."
      ]
    },
    {
      "metadata": {
        "id": "pqY001s4AdpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_random_imgs_labels(X_set, Y_set, n_imgs):\n",
        "  inds = np.random.randint(0, len(X_set), n_imgs)\n",
        "  images, labels = X_set[inds], Y_set[inds]\n",
        "  return images, labels\n",
        "\n",
        "def plot_images(images, labels, preds=None):\n",
        "  fig, axs = plt.subplots(r, c)\n",
        "  cnt = 0\n",
        "  for i in range(r):\n",
        "    for j in range(c):\n",
        "      axs[i, j].imshow(images[cnt], cmap='gray')\n",
        "      axs[i, j].axis('off')\n",
        "      title = labels_names[labels[cnt]] if preds is None else '%s/%s' % (labels_names[labels[cnt]], labels_names[preds[cnt]])\n",
        "      axs[i, j].set_title(title, fontsize=16)\n",
        "      cnt += 1\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NnO5cfBYOahx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's plot some of the images together with their labels to see what the look like"
      ]
    },
    {
      "metadata": {
        "id": "qEBEFVxE5UPl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "images, labels = get_random_imgs_labels(X_train, Y_train, r*c)\n",
        "plot_images(images, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xmto0cDOkLx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we have to build the model we will use to predict the labe of a given image.\n",
        "\n",
        "The model we will use has two fully connected layers and outputs numbers that can be interpreted as probabilities for each one of the ten labels (numbers).\n",
        "\n",
        "We use the label with the highest probability as predicted label."
      ]
    },
    {
      "metadata": {
        "id": "7ZB0aex57iWJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=X_train.shape[1:]),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(len(labels_names), activation='softmax'),\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q_-S7nT9POea",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before we start the training of the model we need to define the target and the way to achieve it.\n",
        "\n",
        "In our case we want the model's predicted probabilities for each label to be as close as possible to the given probabilities for each label. And since in each case we have only one correct label, we want ideally the model to return probability 1 for the correct label and 0 for the rest ones.\n",
        "\n",
        "To ahcieve this we use a *loss function*. In our case the loss function will be the *categorical crossentropy*.\n",
        "\n",
        "Also we need to define a method based upon the model will try to minimize the loss function.\n",
        "\n",
        "The method (also called optimizer since it optimize the model's parameters) that we will use is Adam.\n",
        "\n",
        "We don't need to get into too much details for this one."
      ]
    },
    {
      "metadata": {
        "id": "ahRvgdb0PTCM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7cL-KUfrP6Hj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now the model has been randomly initialized which means that the output will be mostly wrong. Let's see some examples. We can run the next cell more than once to obtain different randomly selected images and the corresponding (true and predicted) labels"
      ]
    },
    {
      "metadata": {
        "id": "utMajqL0_qET",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "images, labels = get_random_imgs_labels(X_val, Y_val, 9)\n",
        "predictions = model.predict_on_batch(images)\n",
        "predictions = np.argmax(predictions, 1)\n",
        "\n",
        "print('correct: %d out of %d' % (np.sum(labels == predictions), len(labels)))\n",
        "plot_images(images, labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SgIiPVedQa3A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's train the model for some epochs (one epoch is one pass through the how training dataset) and see if we get better results.\n",
        "\n",
        "After training the model we can run again the previous cell to obtain the results of the trained model.\n",
        "\n",
        "Of course we can train the model more than once by repeatidly excecuting the next cell and obtain the results by runing the previous one."
      ]
    },
    {
      "metadata": {
        "id": "FN_bprgkFw0T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, to_categorical(Y_train), validation_data=(X_val, to_categorical(Y_val)), epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tMkRFad_Q3mC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "That was it!\n",
        "\n",
        "We trained a model to classify images of handwritten digits.\n",
        "\n",
        "Now a more challenging task will be to classify images of clothes.\n",
        "\n",
        "In order to do this uncomment (delete the #) these lines from the second cell:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# (X_train, Y_train), (X_val, Y_val) = fashion_mnist.load_data()\n",
        "\n",
        "# labels_names = 'T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
        "```\n",
        "\n",
        "You will notice that it will be harder for the model to get very high accuracy and training it more times will not increase the accuracy after a point.\n",
        "\n",
        "In this case we need to make some changes to get better results.\n",
        "\n",
        "These changes could be related to the model (architecture, depth, width), the optimizer, the preprocessing the regularization the loss function etc.\n",
        "\n",
        "## The end\n"
      ]
    }
  ]
}